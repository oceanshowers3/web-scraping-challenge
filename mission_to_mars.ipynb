{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from pprint import pprint \n",
    "import time\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scraped the [NASA Mars News Site](https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest) and collected the latest News Title and Paragraph Text.  \n",
    "- Assign the text to variables that we can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up url for NASA news site, browser, and html\n",
    "news_url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(news_url)\n",
    "news_html = browser.html\n",
    "\n",
    "# parse with BeautifulSoup\n",
    "news_soup = bs(news_html, 'html.parser')\n",
    "\n",
    "# find the latest news article\n",
    "latest_article = news_soup.find('li', class_='slide')\n",
    "\n",
    "# find the latest news article title and print it\n",
    "article_title = latest_article.find('div', class_='content_title').find('a').text\n",
    "time.sleep(2) # sleep before next task \n",
    "\n",
    "# find the latest news article paragraph text and print it\n",
    "article_p = latest_article.find('div', class_='article_teaser_body').text\n",
    "time.sleep(2) # sleep before next task \n",
    "\n",
    "# print the title and the paragraph text\n",
    "print(article_title)\n",
    "print(article_p)\n",
    "time.sleep(2) # sleep before next task "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visit the url for JPL Featured Space Image [here](https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html).\n",
    "- Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url.\n",
    "- Make sure to find the image url to the full size .jpg image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set up url for JPL Featured Mars Image, browser, and html\n",
    "image_url = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html'\n",
    "browser.visit(image_url)\n",
    "image_html = browser.html\n",
    "time.sleep(2) # sleep before next task \n",
    "\n",
    "# go to 'FULL IMAGE', set the new browser link, and html\n",
    "browser.links.find_by_partial_text('FULL IMAGE').first.click()\n",
    "full_image_html = browser.html\n",
    "time.sleep(2) # sleep before next task \n",
    "\n",
    "# parse with BeautifulSoup\n",
    "image_soup = bs(full_image_html, 'html.parser')\n",
    "time.sleep(2) # sleep before next task \n",
    "\n",
    "# scrape the URL\n",
    "feature_url = image_soup.find('img', class_='fancybox-image')['src']\n",
    "time.sleep(2) # sleep before next task \n",
    "\n",
    "# print the url for the full image version of the Featured Mars Image\n",
    "base_url = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/'\n",
    "featured_image_url = f'{base_url}{feature_url}'\n",
    "print(featured_image_url)\n",
    "time.sleep(2) # sleep before next task \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts\n",
    "- Visit the Mars Facts webpage [here](https://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "- Use Pandas to convert the data to an HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up url for Mars Facts and browser\n",
    "facts_url = \"https://space-facts.com/mars/\"\n",
    "browser.visit(facts_url)\n",
    "time.sleep(2) # sleep before next task \n",
    "\n",
    "# use Pandas to parse facts url to find all tables\n",
    "facts_tables = pd.read_html(facts_url)\n",
    "\n",
    "# select the correct table from the list of tables\n",
    "facts_df = facts_tables[0]\n",
    "\n",
    "# rename the columns with appropriate headings\n",
    "facts_df.columns = ['Variable', 'Value']\n",
    "\n",
    "# convert the data to an HTML string\n",
    "facts_string = facts_df.to_html(index=False)\n",
    "print(facts_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres\n",
    "- Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "- Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.\n",
    "- Append the dictionary with the image url string and the hemisphere title to a list. This list contains one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up url for USGS Astrogeology, browser, and html\n",
    "hemispheres_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(hemispheres_url)\n",
    "html_hemispheres = browser.html\n",
    "time.sleep(2) # sleep before next task \n",
    "\n",
    "# parse with BeautifulSoup\n",
    "hemispheres_soup = bs(html_hemispheres, 'html.parser')\n",
    "time.sleep(2) # sleep before next task \n",
    "\n",
    "# retrieve the all items (contains all info for hemispheres)\n",
    "hemispheres_items = hemispheres_soup.find_all('div', class_='item')\n",
    "\n",
    "# empty list for titles and image urls\n",
    "hemispheres_data = []\n",
    "\n",
    "# set up base url\n",
    "hemispheres_base_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "# loop through items containing all the hemispheres' info\n",
    "for item in hemispheres_items: \n",
    "    \n",
    "    # find and store titles\n",
    "    title = item.find('h3').text\n",
    "    \n",
    "    # find link that leads to full res image\n",
    "    hemispheres_full = item.find('a', class_='itemLink product-item')['href']\n",
    "    time.sleep(2) # sleep before next task \n",
    "    \n",
    "    # navigate to site containing full res image\n",
    "    browser.visit(hemispheres_base_url + hemispheres_full)\n",
    "    time.sleep(2) # sleep before next task \n",
    "    \n",
    "    # save the html of site containing each hemisphere's full res image\n",
    "    full_res_url = browser.html\n",
    "    \n",
    "    # parse each hemisphere's html with BeautifulSoup\n",
    "    hemispheres_soup = bs(full_res_url, 'html.parser')\n",
    "    time.sleep(2) # sleep before next task \n",
    "    \n",
    "    # save the path to full res image\n",
    "    full_res_path = hemispheres_soup.find('img', class_='wide-image')['src']\n",
    "    \n",
    "    # save the url to the full res image \n",
    "    img_url = f'{hemispheres_base_url}{full_res_path}'\n",
    "    \n",
    "    # append title and full res image url to hemispheres dictionary\n",
    "    hemispheres_data.append({'Title' : title, 'Link to article' : img_url})  \n",
    "    \n",
    "# print the hemispheres dictionary\n",
    "pprint(hemispheres_data)\n",
    "\n",
    "# close the browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
